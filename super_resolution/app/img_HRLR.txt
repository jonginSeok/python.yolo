# 1. 전체 파이프라인 구조
# ↓ 입력 (Low-Resolution 번호판 이미지)
# ↓ Super-Resolution Network (SR Module)
# ↓ 복원된 High-Resolution 번호판
# ↓ 번호판 인식기 (OCR / LPR Model)
# 출력 (번호판 문자열)

# EDSR (Enhanced Deep SR) : 잔차 블록 기반, 파라미터 효율성이 좋고 품질이 뛰어남
# RCAN (Residual Channel Attention Network) : 채널 Attention을 활용해 텍스트 경계에 집중
# RDN (Residual Dense Network) : Local feature fusion과 dense connection
# ESRGAN (for perceptual quality) : GAN 기반으로 실제처럼 보이게 복원 가능 (번호판에는 부적합한 경우도 있음)

# ✔️ Text-Aware Loss
# Perceptual Loss + OCR Loss + Char-level Consistency Loss
# OCR 모델을 함께 학습하여 실제 문자가 잘 인식되는 방향으로 학습
# ✔️ ROI Alignment or Cropping
# 번호판 영역만 SR 수행 (전체 이미지 아닌 번호판만)
# 이 때 YOLO, Faster R-CNN 등으로 번호판 검출 후 crop
# ✔️ Multi-task 학습 (Joint SR + OCR)
# SR module과 OCR module을 동시에 학습
# 번호판 복원과 동시에 인식까지 수행하며 성능 향상

# 예시 모델 구조: Text Super-Resolution (TSRNet) 구조

# ↓ [Input LR image]
# ↓ [Feature Extractor (e.g., Conv + ResBlocks)]
# ↓ [Residual Blocks + Upsampling (SR core)]
# ↓ [SR Output (HR image)]
# ↓ [OCR Module (CTC-based or CRNN)]
# [Loss: SR loss + OCR loss + Char-aware loss]

# 성능 비교 기준
# PSNR / SSIM : 화질 측정 (객관적)
# OCR Accuracy : 실제 인식 성능
# LPIPS : 인식 기반 유사도 (perceptual)